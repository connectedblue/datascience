---
title: "Human Activity Recognition - Analysis of Weight Lifting Exercise"
author: "Chris Shaw"
date: "22 July 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width = 6, fig.height = 6)
knitr::opts_chunk$set(root.dir="..")
knitr::knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark=",")
})
setwd("..")
library(knitr)
# initialise analysis
library('ProjectTemplate')
load.project()

```



```{r analysis}
# run the analysis code to generate the objects
knitr::read_chunk('../src/rf-model-caret.R')
 
```

# Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices enable people to quantify how much of a particular activity they do, but rarely how well they do it. 

This paper analyses a series of  Weight Lifting Exercises carried out by six young health participants who were fitted with a number of such devices.  They performed one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions:

* ***Class A*** exactly in accordance with the specification
* ***Class B*** throwing the elbows to the front 
* ***Class C*** lifting the dumbbell only halfway 
* ***Class D*** lowering the dumbbell only halfway 
* ***Class E*** throwing the hips to the front

Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.  Measurement data was collected from accelerometers on the belt, forearm, arm, and dumbbell.

A training dataset has been provided which contains the measurement data and the associated class response.  The goal of this analysis is to predict the manner in which participants did the exercise using any of the other variables to predict with. We will describe how the model is built, how cross validation is used, what the expected out of sample error is, and why various choices were made. 

Finally the prediction model will be used to predict 20 different test cases, supplied in a testing set. These will be submitted in the appropriate format for automated checking.

All the R code used in this analysis is reproduced in the Appendix.


# Weight Lifting Exercises Dataset

The training dataset contains `r dim(pml.training)[1]` observation samples and `r dim(pml.training)[2]` columns (the last column **classe** is the outcome). 

The initial investigation into the training data revealed the following structure.

* first 7 columns are identification variables, which determine when and to whom each observation applies.
* The next 152 columns contain measurement data from the devices worn by the participants.  Some of these contained string representations of numbers, so these were converted to numeric.
* The final column is the outcome variable, ***classe***, which we are trying to predict on the testing set
* The testing set was checked to ensure all the columns had the same name and structure.  The only difference in the testing set is that the ***classe*** variable was set to values 1 to 20.  These will be replaced by the predicted values after the analysis.

The following table shows how the data is distributed amongst participants:

```{r trainingsummary}
# Create a table from the appropriate columns in the training summary data
table_contents<-training_summary[c("start_time", "user_name", "exercise_time", "samples","classe")]

# Add a total row at the bottom
table_contents<-rbind(as.matrix(table_contents), c("Total","", "",
                                                   sum(training_summary$samples), ""))
#Print the table
kable(table_contents,
      row.names = FALSE, col.names = c("Date/time of Exercise", "Participant",
                                       "Time taken (secs)", "Samples Collected", "Class"),
      caption = "Summary of the Weight Lifting training dataset",
      align = c("l", "c", "c","r","c"),
      format.args = list(big.mark=","))
```

## Transforming the training set

From the table above, we can see that the participant name and the date of exercise is not related to the outcome class.  The rows are collected in time order, so there's a possibility of a time series connection,  however we assumed not.  So for the subsequent analysis we removed the first seven columns. 

The next task was to examine the number of missing values **NA** in the remaining columns. The following table shows how many columns have missing values, and how many missing values there are.

```{r nacounts}
# Contruct a frequency table of how many NAs are in the columns
na_tab<-cbind(data.frame(c("NA Count", "Number of columns")),t(count(na_sum)))
names(na_tab)<-rep("&nbsp;", ncol(na_tab))
kable(na_tab, row.names = FALSE,  format.args = list(big.mark = ','))
```

We can see that there are 53 columns with no missing values at all.  Of the remainder, the vast majority of observations are missing.  We decided to ignore these columns also in the analysis, and keep only the 53 complete columns.

The code for these transformations is in the appendix.

# Model

Here are the most 15 important predictors in the model.

```{r plotimpvars, fig.width = 10, fig.height = 6}
par(bg="cornsilk")
varImpPlot(caretrf_mod$finalModel, n.var=15, main="15 most important predictive variables\n in the Random Forest model",
            bg="mediumblue")
```

Selection of the best tuning parameters

```{r plottuning, fig.width = 10, fig.height = 6}
par(bg="cornsilk")
plot(caretrf_mod, main="Comparison of accuracy for different mtry")
```




# Appendix

The random forest training:

```{r analysis2, ref.label="analysis", eval=FALSE, echo=TRUE}
```

Producing the summary matrix

```{r summarisetraining, eval=TRUE, echo=FALSE}
knitr::read_chunk('../munge/01-A.R')
```

```{r summarisetraining2, ref.label="summarisetraining", eval=FALSE, echo=TRUE}
```



The initial cleaning routine:

```{r clean, eval=TRUE, echo=FALSE, warning=FALSE}
knitr::read_chunk('../munge/01-A.R')
```

```{r clean2, ref.label="clean", eval=FALSE, echo=TRUE}
```





Reducing the number of measurement columns (removing columns with mostly NA)

```{r reduce, eval=TRUE, echo=FALSE}
knitr::read_chunk('../munge/01-A.R')
```

```{r reduce2, ref.label="reduce", eval=FALSE, echo=TRUE}
```


